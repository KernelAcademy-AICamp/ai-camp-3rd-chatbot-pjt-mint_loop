# Sub-Agent Architecture for TripKit MVP
## Multi-Agent System Design for Production

**"ì‹¤ë¬´ì—ì„œ ê²€ì¦ëœ Sub-Agent ì‹œìŠ¤í…œ ì„¤ê³„"**

---

## ğŸ“‹ Document Information

- **Version**: 1.0.0
- **Last Updated**: 2025-12-04
- **Architecture Pattern**: Multi-Agent Orchestration with LangGraph
- **Related Documents**: [PRD](./PRD_TripKit_MVP.md), [TRD](./TRD_TripKit_MVP.md), [API](./API_Documentation.md)

---

## ğŸ¯ Sub-Agent System Overview

### Design Philosophy

**"ê° ì—ì´ì „íŠ¸ëŠ” ë‹¨ì¼ ì±…ì„ì„ ê°€ì§€ë©°, í˜‘ì—…ì„ í†µí•´ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤"**

### Architecture Pattern

```
Orchestrator Agent (Supervisor)
    â”œâ”€â”€ Conversation Agent (ëŒ€í™” ê´€ë¦¬)
    â”œâ”€â”€ Recommendation Agent (ì¶”ì²œ ìƒì„±)
    â”œâ”€â”€ Image Generation Agent (ì´ë¯¸ì§€ ìƒì„±)
    â”œâ”€â”€ Content Enrichment Agent (ì½˜í…ì¸  ë³´ê°•)
    â””â”€â”€ Quality Assurance Agent (í’ˆì§ˆ ê²€ì¦)
```

### Key Principles

1. **Single Responsibility**: ê° ì—ì´ì „íŠ¸ëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì—­í• 
2. **Loose Coupling**: ì—ì´ì „íŠ¸ ê°„ ë…ë¦½ì„± ìœ ì§€
3. **Asynchronous Communication**: ë¹„ë™ê¸° ë©”ì‹œì§€ ì „ë‹¬
4. **State Management**: LangGraph StateGraph í™œìš©
5. **Error Resilience**: ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ graceful degradation

---

## ğŸ¤– Sub-Agent Specifications

---

## 1. Orchestrator Agent (Supervisor)

**Role**: ì „ì²´ ì›Œí¬í”Œë¡œìš° ì¡°ìœ¨ ë° Sub-Agent ê´€ë¦¬

### Responsibilities

- Sub-Agent ì‘ì—… í• ë‹¹ ë° ìš°ì„ ìˆœìœ„ ê²°ì •
- ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§
- ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ ë¼ìš°íŒ…
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì „ëµ ì‹¤í–‰
- ìµœì¢… ì‘ë‹µ ì¡°í•© ë° ë°˜í™˜

### State Schema

```python
from typing import TypedDict, Literal, List, Dict, Any
from langgraph.graph import add_messages
from langchain_core.messages import BaseMessage

class OrchestratorState(TypedDict):
    """Orchestrator ìƒíƒœ"""
    messages: List[BaseMessage]
    user_request: str
    current_step: Literal["init", "conversation", "recommendation", "image_generation", "enrichment", "qa", "complete"]
    assigned_agents: List[str]
    agent_results: Dict[str, Any]
    errors: List[str]
    final_response: Dict[str, Any] | None
```

### Decision Logic

```python
def route_to_agent(state: OrchestratorState) -> str:
    """ë‹¤ìŒ ì‹¤í–‰í•  ì—ì´ì „íŠ¸ ê²°ì •"""
    step = state["current_step"]

    routing_map = {
        "init": "conversation_agent",
        "conversation": "recommendation_agent",
        "recommendation": "image_generation_agent",
        "image_generation": "content_enrichment_agent",
        "enrichment": "qa_agent",
        "qa": "complete"
    }

    return routing_map.get(step, "complete")
```

### Implementation File

- **Location**: `image-generation-agent/src/orchestrator/supervisor.py`
- **Dependencies**: LangGraph, LangChain
- **MCP Integration**: All MCP servers

---

## 2. Conversation Agent

**Role**: ì‚¬ìš©ì ëŒ€í™” ê´€ë¦¬ ë° Vibe ì¶”ì¶œ

### Responsibilities

- ìì—°ì–´ ëŒ€í™” ì²˜ë¦¬ (5-7 í„´ ëŒ€í™”)
- ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ (mood, aesthetic, duration, interests)
- ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ ë° ê´€ë¦¬
- ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ íŒë‹¨
- êµ¬ì¡°í™”ëœ Vibe í”„ë¡œíŒŒì¼ ìƒì„±

### State Schema

```python
class ConversationState(TypedDict):
    """Conversation Agent ìƒíƒœ"""
    messages: List[BaseMessage]
    session_id: str
    current_question: str
    extracted_preferences: Dict[str, Any]
    conversation_history: List[Dict[str, str]]
    is_complete: bool
    confidence_score: float  # 0.0-1.0
```

### Conversation Flow

```
1. Greeting & Context Setting
   â†“
2. Mood Extraction ("What's your travel mood?")
   â†“
3. Aesthetic Preference ("Urban, nature, vintage, or modern?")
   â†“
4. Duration & Timing ("How long are you traveling?")
   â†“
5. Interest Deep Dive ("Photography, food, art, history?")
   â†“
6. Confirmation & Summary
   â†“
7. Vibe Profile Generation
```

### Prompt Engineering

```python
CONVERSATION_SYSTEM_PROMPT = """
You are a travel vibe consultant for TripKit.

Your goal is to understand the user's emotional and aesthetic preferences
through natural conversation. Extract:
- Mood (romantic, adventurous, nostalgic, peaceful)
- Aesthetic (urban, nature, vintage, modern)
- Duration (short 1-3d, medium 4-7d, long 8+d)
- Interests (photography, food, art, history, nature, architecture)

Guidelines:
- Ask one question at a time
- Be warm, conversational, and inspiring
- Avoid generic travel agent language
- Focus on "vibe" and "feeling" rather than logistics
- Total conversation: 5-7 exchanges maximum
- Confirm understanding before finalizing

Example Questions:
- "What kind of feeling are you looking for in this trip? Romantic sunsets, adventurous exploration, or peaceful reflection?"
- "Are you drawn to urban energy or natural landscapes?"
- "How long do you have for this journey?"
"""
```

### Quality Metrics

- Extraction Accuracy: >85%
- Conversation Completion Rate: >80%
- Average Turns: 5-7
- User Satisfaction: >4.2/5

### Implementation File

- **Location**: `image-generation-agent/src/agents/conversation_agent.py`
- **Dependencies**: GPT-4, LangChain
- **MCP Integration**: Context7 (conversation patterns)

---

## 3. Recommendation Agent

**Role**: Vibe ê¸°ë°˜ ì—¬í–‰ì§€ ë° Hidden Spot ì¶”ì²œ

### Responsibilities

- Vibe í”„ë¡œíŒŒì¼ ë¶„ì„
- ëª©ì ì§€ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
- Hidden Spot ë°œêµ´ (ë¹„ì£¼ë¥˜ ë¡œì»¬ ëª…ì†Œ)
- ì¶”ì²œ ì´ìœ  ìƒì„± (matchReason)
- Photography Score ê³„ì‚°
- ì•ˆì „ë„ ë° ì ‘ê·¼ì„± í‰ê°€

### State Schema

```python
class RecommendationState(TypedDict):
    """Recommendation Agent ìƒíƒœ"""
    vibe_profile: Dict[str, Any]
    destinations: List[Dict[str, Any]]
    hidden_spots: List[Dict[str, Any]]
    selected_concept: Literal["flaneur", "filmlog", "midnight"] | None
    recommendation_reasoning: List[str]
    confidence_scores: Dict[str, float]
```

### Recommendation Algorithm

```python
def generate_recommendations(vibe_profile: Dict) -> List[Destination]:
    """
    Vibe-based recommendation algorithm

    Steps:
    1. Semantic search on destination database (embeddings)
    2. Filter by mood + aesthetic compatibility
    3. Rank by photography_score Ã— vibe_match_score
    4. Diversity filtering (avoid similar destinations)
    5. Generate match_reason for each recommendation
    """

    # 1. Embedding-based search
    query_embedding = get_vibe_embedding(vibe_profile)
    candidate_destinations = vector_search(query_embedding, top_k=20)

    # 2. Filter by compatibility
    compatible_dests = filter_by_vibe_compatibility(
        candidate_destinations,
        vibe_profile
    )

    # 3. Score and rank
    scored_dests = []
    for dest in compatible_dests:
        vibe_score = calculate_vibe_match(dest, vibe_profile)
        photo_score = dest.photography_score / 10
        final_score = (vibe_score * 0.7) + (photo_score * 0.3)

        scored_dests.append({
            **dest,
            "match_score": final_score,
            "match_reason": generate_match_reason(dest, vibe_profile)
        })

    # 4. Diversity filtering
    diverse_dests = select_diverse_destinations(scored_dests, count=3)

    return diverse_dests
```

### Hidden Spot Criteria

**Must Have**:
- âŒ NOT in top-10 tourist lists
- âœ… High photogenic potential (8-10/10)
- âœ… Authentic local atmosphere
- âœ… Accessible by public transport
- âœ… Safe for solo travelers

**Scoring Formula**:
```
hidden_score = (authenticity Ã— 0.4) + (photogenic Ã— 0.3) + (accessibility Ã— 0.2) + (safety Ã— 0.1)
```

### Data Sources

- **Primary**: GPT-4 knowledge base + web search (Tavily)
- **Secondary**: Curated local database (future)
- **Validation**: Cross-reference multiple sources

### Implementation File

- **Location**: `image-generation-agent/src/agents/recommendation_agent.py`
- **Dependencies**: GPT-4, Tavily Search, Vector DB (future)
- **MCP Integration**: Search MCP, Context7

---

## 4. Image Generation Agent

**Role**: Film aesthetic ì´ë¯¸ì§€ ìƒì„±

### Responsibilities

- í”„ë¡¬í”„íŠ¸ ìµœì í™” (location + outfit + film stock)
- DALL-E 3 API í˜¸ì¶œ ë° ì—ëŸ¬ ì²˜ë¦¬
- Film aesthetic ì ìš© (Kodak ColorPlus, Portra, Fuji Superia, Ilford HP5)
- ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì¦
- ìƒì„± ë©”íƒ€ë°ì´í„° ê´€ë¦¬

### State Schema

```python
class ImageGenerationState(TypedDict):
    """Image Generation Agent ìƒíƒœ"""
    location_context: Dict[str, Any]
    concept: str
    film_stock: str
    outfit_style: str
    optimized_prompt: str
    generated_image_url: str | None
    revised_prompt: str | None
    generation_metadata: Dict[str, Any]
    generation_attempts: int
    errors: List[str]
```

### Film Stock Prompts

```python
FILM_STOCK_PROMPTS = {
    "kodak_colorplus": {
        "aesthetic": "Warm, saturated tones with slight red-orange shift",
        "grain": "Fine grain structure, minimal noise",
        "style": "Budget-friendly vintage film look",
        "prompt_suffix": "shot on Kodak ColorPlus 200 film, warm tones, fine grain, slight vignetting, nostalgic atmosphere"
    },
    "kodak_portra": {
        "aesthetic": "Natural, accurate skin tones with subtle pastel colors",
        "grain": "Very fine grain, smooth texture",
        "style": "Professional portrait film aesthetic",
        "prompt_suffix": "shot on Kodak Portra 400 film, natural skin tones, subtle colors, professional quality, smooth grain"
    },
    "fuji_superia": {
        "aesthetic": "Vibrant, saturated colors with strong contrast",
        "grain": "Moderate grain, crisp detail",
        "style": "Bold consumer film look",
        "prompt_suffix": "shot on Fujifilm Superia 400 film, vibrant colors, strong saturation, crisp details, moderate grain"
    },
    "ilford_hp5": {
        "aesthetic": "High contrast black and white with rich tones",
        "grain": "Visible grain structure, dramatic",
        "style": "Classic monochrome film aesthetic",
        "prompt_suffix": "shot on Ilford HP5 Plus 400 black and white film, high contrast, rich blacks, dramatic grain, classic b&w look"
    }
}
```

### Prompt Engineering Template

```python
def build_image_prompt(
    location: Dict,
    concept: str,
    film_stock: str,
    outfit: str
) -> str:
    """
    DALL-E 3 í”„ë¡¬í”„íŠ¸ ìƒì„±

    Template Structure:
    1. Film aesthetic declaration
    2. Scene description (location)
    3. Subject description (person + outfit + camera)
    4. Composition and framing
    5. Lighting and mood
    6. Film stock characteristics
    """

    film_config = FILM_STOCK_PROMPTS[film_stock]

    prompt = f"""
Create a high-quality photograph in the style of {film_config['aesthetic']}.

Scene Description:
{location['description']}

Subject:
- Young person wearing {outfit}
- Holding vintage 35mm film camera (Canon AE-1 or similar)
- Natural, candid pose looking towards the scenery
- Gentle, genuine expression

Composition:
- Subject positioned in right third of frame
- {location['name']} in background
- Depth of field: f/1.8-2.8 for beautiful bokeh
- Natural framing with environmental elements

Lighting & Mood:
- {get_lighting_for_time(location.get('best_time_to_visit', 'golden hour'))}
- Authentic analog film atmosphere
- Nostalgic, cinematic quality

Film Aesthetic:
{film_config['prompt_suffix']}

Style: Highly detailed, professional film photography, authentic vintage look, NOT digital filter simulation.
"""

    return prompt.strip()
```

### Error Handling

```python
async def generate_with_retry(
    prompt: str,
    max_attempts: int = 3
) -> Dict[str, Any]:
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì´ë¯¸ì§€ ìƒì„±"""

    for attempt in range(max_attempts):
        try:
            response = await openai_client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="hd",
                style="vivid",
                n=1
            )

            return {
                "url": response.data[0].url,
                "revised_prompt": response.data[0].revised_prompt,
                "attempts": attempt + 1,
                "success": True
            }

        except openai.BadRequestError as e:
            # Content policy violation
            if "content_policy" in str(e).lower():
                # Sanitize prompt and retry
                prompt = sanitize_prompt(prompt)
                continue
            raise

        except openai.RateLimitError:
            # Wait and retry
            await asyncio.sleep(2 ** attempt)  # Exponential backoff
            continue

        except Exception as e:
            logger.error(f"Image generation attempt {attempt + 1} failed: {e}")
            if attempt == max_attempts - 1:
                raise

    return {"success": False, "error": "Max retries exceeded"}
```

### Quality Validation

```python
def validate_image_quality(image_url: str) -> bool:
    """ìƒì„±ëœ ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì¦"""

    # 1. URL ìœ íš¨ì„± í™•ì¸
    if not image_url or not image_url.startswith("https://"):
        return False

    # 2. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    try:
        response = requests.get(image_url, timeout=10)
        image = Image.open(BytesIO(response.content))

        # 3. ê¸°ë³¸ ê²€ì¦
        width, height = image.size
        if width < 1024 or height < 1024:
            return False

        # 4. í’ˆì§ˆ ê²€ì¦ (future: ML-based quality assessment)
        # - ì–¼êµ´ ê²€ì¶œ
        # - Film grain ì¡´ì¬ ì—¬ë¶€
        # - ìƒ‰ìƒ í”„ë¡œíŒŒì¼ ì¼ì¹˜ë„

        return True

    except Exception as e:
        logger.error(f"Image validation failed: {e}")
        return False
```

### Implementation File

- **Location**: `image-generation-agent/src/agents/image_generation_agent.py`
- **Dependencies**: DALL-E 3, Pillow
- **MCP Integration**: Image MCP Server

---

## 5. Content Enrichment Agent

**Role**: ì¶”ì²œ ì½˜í…ì¸  ë³´ê°• ë° ìŠ¤íƒ€ì¼ë§ íŒ¨í‚¤ì§€ ìƒì„±

### Responsibilities

- Film camera ì¶”ì²œ (ëª¨ë¸, íŠ¹ì„±, ëŒ€ì—¬ ì •ë³´)
- Camera settings ìƒì„± (aperture, shutter speed, ISO)
- Outfit styling íë ˆì´ì…˜ (ìƒ‰ìƒ íŒ”ë ˆíŠ¸, êµ¬ì²´ì  ì•„ì´í…œ)
- Props ì¶”ì²œ (2-3ê°œ ì†Œí’ˆ)
- Photography angles ê°€ì´ë“œ (3-5ê°œ êµ¬ë„ ê¸°ë²•)
- Local insider tips ì¶”ê°€

### State Schema

```python
class ContentEnrichmentState(TypedDict):
    """Content Enrichment Agent ìƒíƒœ"""
    location_id: str
    concept: str
    time_of_day: str
    weather: str
    season: str

    # Generated content
    camera_recommendation: Dict[str, Any]
    film_stock_recommendation: Dict[str, Any]
    camera_settings: Dict[str, Any]
    outfit_suggestions: Dict[str, Any]
    props: List[Dict[str, Any]]
    best_angles: List[Dict[str, Any]]
    local_tips: Dict[str, str]
```

### Camera Recommendation Logic

```python
CAMERA_DATABASE = {
    "flaneur": {
        "primary": "Leica M6",
        "alternative": ["Olympus Trip 35", "Contax T2"],
        "reasoning": "Compact, discreet cameras for urban wandering"
    },
    "filmlog": {
        "primary": "Canon AE-1",
        "alternative": ["Nikon FM2", "Pentax K1000"],
        "reasoning": "Reliable SLRs with manual controls for vintage aesthetic"
    },
    "midnight": {
        "primary": "Hasselblad 500C/M",
        "alternative": ["Mamiya RB67", "Pentax 67"],
        "reasoning": "Medium format for artistic, dreamlike quality"
    }
}

def recommend_camera(concept: str, budget: str = "medium") -> Dict:
    """Concept ê¸°ë°˜ ì¹´ë©”ë¼ ì¶”ì²œ"""

    config = CAMERA_DATABASE.get(concept, CAMERA_DATABASE["filmlog"])

    return {
        "model": config["primary"],
        "alternatives": config["alternative"],
        "reasoning": config["reasoning"],
        "rental_info": get_rental_info(config["primary"]),
        "buy_links": get_purchase_links(config["primary"])
    }
```

### Outfit Styling Algorithm

```python
def generate_outfit_suggestions(
    concept: str,
    season: str,
    weather: str,
    color_preferences: List[str] = None
) -> Dict:
    """Conceptì™€ ê³„ì ˆ ê¸°ë°˜ ìŠ¤íƒ€ì¼ë§ ìƒì„±"""

    # 1. Color palette generation
    base_palettes = {
        "flaneur": ["#2C3E50", "#ECF0F1", "#34495E", "#BDC3C7"],  # Urban neutrals
        "filmlog": ["#F5E6D3", "#8B7355", "#A0826D", "#FFFFFF"],  # Vintage warm
        "midnight": ["#191970", "#4B0082", "#2F4F4F", "#C0C0C0"]  # Artistic dark
    }

    palette = base_palettes.get(concept, base_palettes["filmlog"])

    # 2. Seasonal adjustments
    seasonal_modifiers = {
        "spring": {"add_colors": ["pastel pink", "light green"], "fabrics": ["cotton", "linen"]},
        "summer": {"add_colors": ["white", "light blue"], "fabrics": ["linen", "breathable cotton"]},
        "fall": {"add_colors": ["burgundy", "mustard"], "fabrics": ["wool", "denim"]},
        "winter": {"add_colors": ["navy", "charcoal"], "fabrics": ["wool", "cashmere"]}
    }

    season_config = seasonal_modifiers.get(season, seasonal_modifiers["spring"])

    # 3. Specific item generation
    items = generate_specific_items(concept, season, weather)

    return {
        "color_palette": palette,
        "color_names": get_color_names(palette),
        "seasonal_additions": season_config["add_colors"],
        "recommended_fabrics": season_config["fabrics"],
        "specific_items": items,
        "avoid_items": get_avoid_items(concept),
        "shopping_tips": generate_shopping_tips(concept)
    }
```

### Props Recommendation

```python
PROPS_DATABASE = {
    "flaneur": [
        {"name": "Vintage book", "purpose": "Literary wanderer aesthetic"},
        {"name": "City map", "purpose": "Navigation storytelling element"},
        {"name": "Coffee in thermos", "purpose": "Urban explorer vibe"}
    ],
    "filmlog": [
        {"name": "Vintage Polaroid camera", "purpose": "Nostalgic layering"},
        {"name": "Film photography book", "purpose": "Artistic context"},
        {"name": "Woven basket", "purpose": "Vintage travel charm"}
    ],
    "midnight": [
        {"name": "Vintage pocket watch", "purpose": "Time travel symbolism"},
        {"name": "Leather-bound journal", "purpose": "Artistic documentation"},
        {"name": "Antique monocular", "purpose": "Poetic observation tool"}
    ]
}

def recommend_props(
    concept: str,
    location_type: str,
    count: int = 3
) -> List[Dict]:
    """Concept ê¸°ë°˜ ì†Œí’ˆ ì¶”ì²œ"""

    base_props = PROPS_DATABASE.get(concept, PROPS_DATABASE["filmlog"])

    # Location-specific adjustments
    if location_type == "coastal":
        base_props.append({
            "name": "Seashell collection jar",
            "purpose": "Coastal memory keeper"
        })
    elif location_type == "urban":
        base_props.append({
            "name": "Vintage metro ticket",
            "purpose": "Urban exploration token"
        })

    # Select top props
    selected = base_props[:count]

    # Enrich with sourcing info
    for prop in selected:
        prop["where_to_find"] = generate_sourcing_info(prop["name"])
        prop["styling_tips"] = generate_styling_tips(prop["name"], concept)

    return selected
```

### Photography Angles Guide

```python
def generate_photography_angles(
    location: Dict,
    concept: str,
    time_of_day: str
) -> List[Dict]:
    """ì´¬ì˜ êµ¬ë„ ê°€ì´ë“œ ìƒì„±"""

    base_angles = [
        {
            "name": "Rule of thirds",
            "description": "Position subject in third intersections",
            "camera_height": "eye-level",
            "best_lighting": "golden hour",
            "diagram_type": "grid_overlay"
        },
        {
            "name": "Leading lines",
            "description": "Use natural lines to guide viewer's eye",
            "camera_height": "low angle",
            "best_lighting": "any",
            "diagram_type": "line_overlay"
        },
        {
            "name": "Bokeh background",
            "description": "Wide aperture for creamy background blur",
            "camera_height": "eye-level or above",
            "best_lighting": "soft diffused",
            "diagram_type": "focus_diagram"
        },
        {
            "name": "Silhouette",
            "description": "Backlit subject against bright background",
            "camera_height": "low angle",
            "best_lighting": "sunset/sunrise",
            "diagram_type": "exposure_diagram"
        },
        {
            "name": "Frame within frame",
            "description": "Use environmental elements as natural frame",
            "camera_height": "varies",
            "best_lighting": "any",
            "diagram_type": "composition_overlay"
        }
    ]

    # Time-of-day specific recommendations
    time_based_angles = filter_angles_by_time(base_angles, time_of_day)

    # Concept-specific adjustments
    concept_angles = adjust_for_concept(time_based_angles, concept)

    # Add visual examples and diagrams
    for angle in concept_angles:
        angle["visual_example"] = f"https://angles.tripkit.com/{angle['name']}.jpg"
        angle["diagram_url"] = f"https://angles.tripkit.com/diagrams/{angle['diagram_type']}.svg"
        angle["technique"] = generate_technique_description(angle, location)

    return concept_angles[:5]  # Top 5 angles
```

### Implementation File

- **Location**: `image-generation-agent/src/agents/content_enrichment_agent.py`
- **Dependencies**: GPT-4, Database (film stocks, cameras)
- **MCP Integration**: Context7 (photography knowledge)

---

## 6. Quality Assurance Agent

**Role**: ìƒì„±ëœ ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ ë° ê°œì„ 

### Responsibilities

- ì¶”ì²œ ì •í™•ë„ ê²€ì¦ (vibe match í™•ì¸)
- ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ (film aesthetic ì í•©ì„±)
- ì½˜í…ì¸  ì™„ì„±ë„ ì²´í¬ (í•„ìˆ˜ í•„ë“œ ëˆ„ë½ í™•ì¸)
- ì•ˆì „ì„± ê²€ì¦ (ë¶€ì ì ˆí•œ ì½˜í…ì¸  í•„í„°ë§)
- ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° í•™ìŠµ

### State Schema

```python
class QualityAssuranceState(TypedDict):
    """Quality Assurance Agent ìƒíƒœ"""
    content_to_validate: Dict[str, Any]
    validation_results: Dict[str, bool]
    quality_scores: Dict[str, float]
    improvement_suggestions: List[str]
    is_approved: bool
    confidence_level: float
```

### Validation Checklist

```python
class QAChecklist:
    """í’ˆì§ˆ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸"""

    @staticmethod
    def validate_recommendations(destinations: List[Dict]) -> Dict:
        """ì¶”ì²œ ì½˜í…ì¸  ê²€ì¦"""

        checks = {
            "count": len(destinations) == 3,
            "all_have_match_reason": all(d.get("matchReason") for d in destinations),
            "photography_scores": all(1 <= d.get("photographyScore", 0) <= 10 for d in destinations),
            "safety_ratings": all(1 <= d.get("safetyRating", 0) <= 10 for d in destinations),
            "descriptions_length": all(50 <= len(d.get("description", "")) <= 300 for d in destinations),
            "no_duplicates": len(set(d["id"] for d in destinations)) == len(destinations)
        }

        return {
            "passed": all(checks.values()),
            "checks": checks,
            "quality_score": sum(checks.values()) / len(checks)
        }

    @staticmethod
    def validate_image(image_data: Dict) -> Dict:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì¦"""

        checks = {
            "url_valid": bool(image_data.get("url") and image_data["url"].startswith("https://")),
            "prompt_exists": bool(image_data.get("prompt")),
            "metadata_complete": all(
                key in image_data.get("metadata", {})
                for key in ["model", "size", "quality"]
            ),
            "generation_time_acceptable": image_data.get("generationTime", 99999) < 30000  # <30s
        }

        return {
            "passed": all(checks.values()),
            "checks": checks,
            "quality_score": sum(checks.values()) / len(checks)
        }

    @staticmethod
    def validate_styling_package(styling: Dict) -> Dict:
        """ìŠ¤íƒ€ì¼ë§ íŒ¨í‚¤ì§€ ê²€ì¦"""

        checks = {
            "camera_recommended": bool(styling.get("cameraModel")),
            "film_stock_complete": bool(styling.get("filmStock") and styling["filmStock"].get("name")),
            "camera_settings_valid": all(
                key in styling.get("cameraSettings", {})
                for key in ["aperture", "shutterSpeed", "iso"]
            ),
            "outfit_has_palette": bool(styling.get("outfitSuggestions", {}).get("colorPalette")),
            "props_count": 2 <= len(styling.get("props", [])) <= 4,
            "angles_count": 3 <= len(styling.get("bestAngles", [])) <= 5
        }

        return {
            "passed": all(checks.values()),
            "checks": checks,
            "quality_score": sum(checks.values()) / len(checks)
        }
```

### Safety Validation

```python
async def validate_safety(content: Dict) -> Dict:
    """ì•ˆì „ì„± ê²€ì¦ (ë¶€ì ì ˆí•œ ì½˜í…ì¸  í•„í„°ë§)"""

    # 1. Text content moderation
    text_to_check = " ".join([
        str(v) for v in content.values()
        if isinstance(v, (str, list))
    ])

    moderation_result = await openai_client.moderations.create(
        input=text_to_check
    )

    # 2. Image URL validation (if present)
    image_safe = True
    if content.get("generated_image_url"):
        # Check image content (future: use moderation API)
        image_safe = True  # Placeholder

    return {
        "text_safe": not moderation_result.results[0].flagged,
        "image_safe": image_safe,
        "categories": moderation_result.results[0].categories,
        "approved": not moderation_result.results[0].flagged and image_safe
    }
```

### Improvement Suggestions

```python
def generate_improvements(validation_results: Dict) -> List[str]:
    """ê²€ì¦ ê²°ê³¼ ê¸°ë°˜ ê°œì„  ì œì•ˆ"""

    suggestions = []

    # Check each validation result
    for category, result in validation_results.items():
        if not result.get("passed"):
            failed_checks = [
                check for check, passed in result.get("checks", {}).items()
                if not passed
            ]

            for check in failed_checks:
                suggestions.append(
                    get_improvement_suggestion(category, check)
                )

    # Quality score-based suggestions
    overall_quality = sum(
        r.get("quality_score", 0)
        for r in validation_results.values()
    ) / len(validation_results)

    if overall_quality < 0.8:
        suggestions.append(
            "Overall quality below threshold. Consider regenerating content."
        )

    return suggestions
```

### Implementation File

- **Location**: `image-generation-agent/src/agents/qa_agent.py`
- **Dependencies**: OpenAI Moderation API
- **MCP Integration**: Sequential (systematic validation)

---

## ğŸ”„ Agent Communication & Workflow

### Message Passing Protocol

```python
from typing import TypedDict, Literal
from datetime import datetime

class AgentMessage(TypedDict):
    """ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ í”„ë¡œí† ì½œ"""
    sender: str  # Agent ID
    receiver: str  # Target agent ID or "orchestrator"
    message_type: Literal["request", "response", "error", "status"]
    payload: Dict[str, Any]
    timestamp: datetime
    correlation_id: str  # Request tracking
    priority: Literal["high", "normal", "low"]
```

### Workflow State Machine

```python
from langgraph.graph import StateGraph, END

def build_multi_agent_workflow():
    """Multi-Agent ì›Œí¬í”Œë¡œìš° êµ¬ì¶•"""

    workflow = StateGraph(OrchestratorState)

    # Add agent nodes
    workflow.add_node("conversation", conversation_agent_node)
    workflow.add_node("recommendation", recommendation_agent_node)
    workflow.add_node("image_generation", image_generation_agent_node)
    workflow.add_node("content_enrichment", content_enrichment_agent_node)
    workflow.add_node("qa", qa_agent_node)

    # Define edges
    workflow.set_entry_point("conversation")

    workflow.add_conditional_edges(
        "conversation",
        lambda state: "recommendation" if state.get("is_complete") else "conversation"
    )

    workflow.add_edge("recommendation", "image_generation")
    workflow.add_edge("image_generation", "content_enrichment")
    workflow.add_edge("content_enrichment", "qa")

    workflow.add_conditional_edges(
        "qa",
        lambda state: END if state.get("is_approved") else "content_enrichment"
    )

    return workflow.compile()
```

### Parallel Execution Pattern

```python
import asyncio

async def parallel_agent_execution(
    agents: List[Callable],
    state: Dict[str, Any]
) -> List[Dict]:
    """ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰"""

    tasks = [
        asyncio.create_task(agent(state))
        for agent in agents
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Handle errors
    successful_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"Agent {agents[i].__name__} failed: {result}")
        else:
            successful_results.append(result)

    return successful_results
```

---

## ğŸ“‚ Project Structure

```
image-generation-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ supervisor.py              # Orchestrator Agent
â”‚   â”‚   â””â”€â”€ state.py                   # Global state definitions
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conversation_agent.py      # Conversation Agent
â”‚   â”‚   â”œâ”€â”€ recommendation_agent.py    # Recommendation Agent
â”‚   â”‚   â”œâ”€â”€ image_generation_agent.py  # Image Generation Agent
â”‚   â”‚   â”œâ”€â”€ content_enrichment_agent.py # Content Enrichment Agent
â”‚   â”‚   â””â”€â”€ qa_agent.py                # Quality Assurance Agent
â”‚   â”‚
â”‚   â”œâ”€â”€ mcp_servers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search_server.py           # Search MCP Server
â”‚   â”‚   â””â”€â”€ image_server.py            # Image Generation MCP Server
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ message_protocol.py        # Agent message protocol
â”‚   â”‚   â”œâ”€â”€ state_management.py        # State utilities
â”‚   â”‚   â””â”€â”€ error_handling.py          # Error handling utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py                # Configuration
â”‚   â”‚   â”œâ”€â”€ prompts.py                 # Prompt templates
â”‚   â”‚   â””â”€â”€ constants.py               # Constants and enums
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py                 # Logging utilities
â”‚       â””â”€â”€ monitoring.py              # Monitoring and metrics
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_conversation_agent.py
â”‚   â”‚   â”œâ”€â”€ test_recommendation_agent.py
â”‚   â”‚   â”œâ”€â”€ test_image_generation_agent.py
â”‚   â”‚   â”œâ”€â”€ test_content_enrichment_agent.py
â”‚   â”‚   â””â”€â”€ test_qa_agent.py
â”‚   â”‚
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ test_full_workflow.py
â”‚       â””â”€â”€ test_agent_communication.py
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_workflow.py              # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì˜ˆì œ
â”‚   â”œâ”€â”€ parallel_agents.py             # ë³‘ë ¬ ì‹¤í–‰ ì˜ˆì œ
â”‚   â””â”€â”€ custom_workflow.py             # ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì˜ˆì œ
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ agent_specifications/          # ê° ì—ì´ì „íŠ¸ ìƒì„¸ ë¬¸ì„œ
    â””â”€â”€ workflow_diagrams/             # ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨
```

---

## ğŸš€ Implementation Plan

### Phase 1: Core Infrastructure (Week 1)

1. **Orchestrator Setup**
   - StateGraph êµ¬ì¡° ì„¤ê³„
   - Message protocol êµ¬í˜„
   - Error handling framework

2. **Agent Scaffolding**
   - ê° ì—ì´ì „íŠ¸ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
   - State schema ì •ì˜
   - Node í•¨ìˆ˜ í…œí”Œë¦¿

### Phase 2: Individual Agents (Week 2-3)

1. **Conversation Agent** (2 days)
   - Prompt engineering
   - Vibe extraction logic
   - Conversation flow management

2. **Recommendation Agent** (3 days)
   - Vibe matching algorithm
   - Hidden spot generation
   - Scoring and ranking

3. **Image Generation Agent** (2 days)
   - Film stock prompts
   - DALL-E 3 integration
   - Quality validation

4. **Content Enrichment Agent** (2 days)
   - Camera recommendations
   - Styling generation
   - Photography angles

5. **Quality Assurance Agent** (2 days)
   - Validation logic
   - Safety checks
   - Improvement suggestions

### Phase 3: Integration & Testing (Week 4)

1. **Agent Integration**
   - Workflow assembly
   - Message passing
   - Error recovery

2. **Testing**
   - Unit tests per agent
   - Integration tests
   - End-to-end workflow tests

3. **Optimization**
   - Performance tuning
   - Parallel execution
   - Caching strategies

---

## ğŸ“Š Success Metrics

### Agent Performance KPIs

| Agent | Metric | Target |
|-------|--------|--------|
| Conversation | Extraction Accuracy | >85% |
| Conversation | Completion Rate | >80% |
| Recommendation | Vibe Match Score | >0.75 |
| Recommendation | Hidden Spot Quality | >8/10 |
| Image Generation | Success Rate | >90% |
| Image Generation | Generation Time | <15s |
| Content Enrichment | Completeness | >95% |
| QA | Approval Rate (first pass) | >80% |

### System-Level Metrics

- **End-to-End Success Rate**: >85%
- **Average Workflow Time**: <60s
- **Error Recovery Rate**: >90%
- **User Satisfaction**: >4.2/5

---

## ğŸ”§ Configuration & Deployment

### Environment Variables

```bash
# Agent Configuration
ORCHESTRATOR_MAX_RETRIES=3
AGENT_TIMEOUT_SECONDS=30
PARALLEL_EXECUTION_ENABLED=true
MAX_CONCURRENT_AGENTS=5

# Model Configuration
CONVERSATION_MODEL=gpt-4o
RECOMMENDATION_MODEL=gpt-4o
ENRICHMENT_MODEL=gpt-4o-mini
IMAGE_MODEL=dall-e-3

# MCP Servers
SEARCH_MCP_URL=http://localhost:8050
IMAGE_MCP_URL=http://localhost:8051

# Monitoring
ENABLE_METRICS=true
LOG_LEVEL=INFO
SENTRY_DSN=https://...
```

### Docker Compose

```yaml
version: '3.8'

services:
  orchestrator:
    build: .
    environment:
      - AGENT_TYPE=orchestrator
    ports:
      - "8080:8080"
    depends_on:
      - search-mcp
      - image-mcp

  search-mcp:
    build:
      context: .
      dockerfile: Dockerfile.search-mcp
    ports:
      - "8050:8050"

  image-mcp:
    build:
      context: .
      dockerfile: Dockerfile.image-mcp
    ports:
      - "8051:8051"
```

---

## ğŸ“š References

- [LangGraph Multi-Agent Systems](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)
- [Agent-to-Agent (A2A) Protocol](https://github.com/anthropics/a2a)
- [FastMCP Documentation](https://github.com/jlowin/fastmcp)
- [OpenAI API Best Practices](https://platform.openai.com/docs/guides/best-practices)

---

**Document Status**: âœ… Ready for Implementation
**Next Steps**: Begin Phase 1 - Core Infrastructure Setup
